{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e00493",
   "metadata": {},
   "source": [
    "# Replication of the optimal strategy on other node\n",
    "\n",
    "\n",
    "The idea is that nodes have specifities due to their location (whether they are close to a specific type of generator or node).\n",
    "\n",
    "Therefore, we study how would be the asset profits on other nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f3cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf53d87",
   "metadata": {},
   "source": [
    "## download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5b5b033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARKET_DAY</th>\n",
       "      <th>NODE</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>HE1</th>\n",
       "      <th>HE2</th>\n",
       "      <th>HE3</th>\n",
       "      <th>HE4</th>\n",
       "      <th>HE5</th>\n",
       "      <th>HE6</th>\n",
       "      <th>...</th>\n",
       "      <th>HE15</th>\n",
       "      <th>HE16</th>\n",
       "      <th>HE17</th>\n",
       "      <th>HE18</th>\n",
       "      <th>HE19</th>\n",
       "      <th>HE20</th>\n",
       "      <th>HE21</th>\n",
       "      <th>HE22</th>\n",
       "      <th>HE23</th>\n",
       "      <th>HE24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>AMIL.PSGC1.AMP</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>15.72</td>\n",
       "      <td>20.09</td>\n",
       "      <td>27.47</td>\n",
       "      <td>38.75</td>\n",
       "      <td>41.85</td>\n",
       "      <td>44.41</td>\n",
       "      <td>...</td>\n",
       "      <td>49.06</td>\n",
       "      <td>53.68</td>\n",
       "      <td>48.43</td>\n",
       "      <td>50.93</td>\n",
       "      <td>52.24</td>\n",
       "      <td>46.76</td>\n",
       "      <td>34.17</td>\n",
       "      <td>30.51</td>\n",
       "      <td>-5.31</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>EES.NINEMILE4</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>60.83</td>\n",
       "      <td>40.59</td>\n",
       "      <td>39.74</td>\n",
       "      <td>40.94</td>\n",
       "      <td>43.85</td>\n",
       "      <td>46.33</td>\n",
       "      <td>...</td>\n",
       "      <td>54.44</td>\n",
       "      <td>58.58</td>\n",
       "      <td>52.77</td>\n",
       "      <td>55.43</td>\n",
       "      <td>55.80</td>\n",
       "      <td>49.87</td>\n",
       "      <td>42.46</td>\n",
       "      <td>42.85</td>\n",
       "      <td>42.81</td>\n",
       "      <td>38.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>EES.SAN_JC1_CT</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>57.03</td>\n",
       "      <td>38.22</td>\n",
       "      <td>37.66</td>\n",
       "      <td>39.19</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.44</td>\n",
       "      <td>...</td>\n",
       "      <td>51.84</td>\n",
       "      <td>56.21</td>\n",
       "      <td>50.79</td>\n",
       "      <td>53.32</td>\n",
       "      <td>53.74</td>\n",
       "      <td>47.81</td>\n",
       "      <td>40.47</td>\n",
       "      <td>40.25</td>\n",
       "      <td>39.58</td>\n",
       "      <td>36.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>MEC.PPWIND</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.56</td>\n",
       "      <td>22.91</td>\n",
       "      <td>31.33</td>\n",
       "      <td>36.5</td>\n",
       "      <td>39.35</td>\n",
       "      <td>...</td>\n",
       "      <td>44.43</td>\n",
       "      <td>48.91</td>\n",
       "      <td>44.05</td>\n",
       "      <td>46.74</td>\n",
       "      <td>48.06</td>\n",
       "      <td>41.5</td>\n",
       "      <td>26.21</td>\n",
       "      <td>30.87</td>\n",
       "      <td>18.47</td>\n",
       "      <td>21.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>NSP.NWELOAD</td>\n",
       "      <td>Loadzone</td>\n",
       "      <td>LMP</td>\n",
       "      <td>17.69</td>\n",
       "      <td>13.95</td>\n",
       "      <td>22.03</td>\n",
       "      <td>33.19</td>\n",
       "      <td>39.61</td>\n",
       "      <td>42.65</td>\n",
       "      <td>...</td>\n",
       "      <td>48.88</td>\n",
       "      <td>53.17</td>\n",
       "      <td>47.95</td>\n",
       "      <td>50.86</td>\n",
       "      <td>52.23</td>\n",
       "      <td>46.37</td>\n",
       "      <td>38.11</td>\n",
       "      <td>35.04</td>\n",
       "      <td>22.29</td>\n",
       "      <td>24.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>3/31/2025</td>\n",
       "      <td>EES.NINEMILE4</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>26.27</td>\n",
       "      <td>24.14</td>\n",
       "      <td>23.95</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.11</td>\n",
       "      <td>27.06</td>\n",
       "      <td>...</td>\n",
       "      <td>31.89</td>\n",
       "      <td>62.83</td>\n",
       "      <td>43.67</td>\n",
       "      <td>43.01</td>\n",
       "      <td>196.30</td>\n",
       "      <td>66.74</td>\n",
       "      <td>49.73</td>\n",
       "      <td>82.25</td>\n",
       "      <td>32.77</td>\n",
       "      <td>28.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>3/31/2025</td>\n",
       "      <td>EES.SAN_JC1_CT</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>24.41</td>\n",
       "      <td>23.57</td>\n",
       "      <td>23.52</td>\n",
       "      <td>24.56</td>\n",
       "      <td>24.58</td>\n",
       "      <td>27.97</td>\n",
       "      <td>...</td>\n",
       "      <td>31.89</td>\n",
       "      <td>44.34</td>\n",
       "      <td>35.48</td>\n",
       "      <td>37.34</td>\n",
       "      <td>246.87</td>\n",
       "      <td>69.66</td>\n",
       "      <td>51.21</td>\n",
       "      <td>84.2</td>\n",
       "      <td>33.16</td>\n",
       "      <td>28.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5475</th>\n",
       "      <td>3/31/2025</td>\n",
       "      <td>MEC.PPWIND</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>13.54</td>\n",
       "      <td>17.43</td>\n",
       "      <td>19.96</td>\n",
       "      <td>20.52</td>\n",
       "      <td>20.6</td>\n",
       "      <td>23.45</td>\n",
       "      <td>...</td>\n",
       "      <td>29.69</td>\n",
       "      <td>29.34</td>\n",
       "      <td>28.31</td>\n",
       "      <td>30.46</td>\n",
       "      <td>193.58</td>\n",
       "      <td>66.42</td>\n",
       "      <td>48.51</td>\n",
       "      <td>80.84</td>\n",
       "      <td>31.97</td>\n",
       "      <td>26.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>3/31/2025</td>\n",
       "      <td>NSP.NWELOAD</td>\n",
       "      <td>Loadzone</td>\n",
       "      <td>LMP</td>\n",
       "      <td>18.81</td>\n",
       "      <td>22.40</td>\n",
       "      <td>25.69</td>\n",
       "      <td>26.75</td>\n",
       "      <td>26.32</td>\n",
       "      <td>29.12</td>\n",
       "      <td>...</td>\n",
       "      <td>31.71</td>\n",
       "      <td>30.91</td>\n",
       "      <td>30.54</td>\n",
       "      <td>31.3</td>\n",
       "      <td>200.14</td>\n",
       "      <td>69.53</td>\n",
       "      <td>52.47</td>\n",
       "      <td>89.8</td>\n",
       "      <td>36.32</td>\n",
       "      <td>30.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5477</th>\n",
       "      <td>3/31/2025</td>\n",
       "      <td>NSP.PRISL1</td>\n",
       "      <td>Gennode</td>\n",
       "      <td>LMP</td>\n",
       "      <td>15.76</td>\n",
       "      <td>19.10</td>\n",
       "      <td>21.71</td>\n",
       "      <td>22.45</td>\n",
       "      <td>22.36</td>\n",
       "      <td>24.99</td>\n",
       "      <td>...</td>\n",
       "      <td>28.27</td>\n",
       "      <td>27.18</td>\n",
       "      <td>26.74</td>\n",
       "      <td>28.21</td>\n",
       "      <td>179.83</td>\n",
       "      <td>62.16</td>\n",
       "      <td>46.32</td>\n",
       "      <td>78.85</td>\n",
       "      <td>31.85</td>\n",
       "      <td>27.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5478 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MARKET_DAY            NODE      TYPE VALUE    HE1    HE2    HE3    HE4  \\\n",
       "0     10/1/2022  AMIL.PSGC1.AMP   Gennode   LMP  15.72  20.09  27.47  38.75   \n",
       "1     10/1/2022   EES.NINEMILE4   Gennode   LMP  60.83  40.59  39.74  40.94   \n",
       "2     10/1/2022  EES.SAN_JC1_CT   Gennode   LMP  57.03  38.22  37.66  39.19   \n",
       "3     10/1/2022      MEC.PPWIND   Gennode   LMP  21.37  17.56  22.91  31.33   \n",
       "4     10/1/2022     NSP.NWELOAD  Loadzone   LMP  17.69  13.95  22.03  33.19   \n",
       "...         ...             ...       ...   ...    ...    ...    ...    ...   \n",
       "5473  3/31/2025   EES.NINEMILE4   Gennode   LMP  26.27  24.14  23.95  24.30   \n",
       "5474  3/31/2025  EES.SAN_JC1_CT   Gennode   LMP  24.41  23.57  23.52  24.56   \n",
       "5475  3/31/2025      MEC.PPWIND   Gennode   LMP  13.54  17.43  19.96  20.52   \n",
       "5476  3/31/2025     NSP.NWELOAD  Loadzone   LMP  18.81  22.40  25.69  26.75   \n",
       "5477  3/31/2025      NSP.PRISL1   Gennode   LMP  15.76  19.10  21.71  22.45   \n",
       "\n",
       "        HE5    HE6  ...   HE15   HE16   HE17   HE18    HE19   HE20   HE21  \\\n",
       "0     41.85  44.41  ...  49.06  53.68  48.43  50.93   52.24  46.76  34.17   \n",
       "1     43.85  46.33  ...  54.44  58.58  52.77  55.43   55.80  49.87  42.46   \n",
       "2      42.0  44.44  ...  51.84  56.21  50.79  53.32   53.74  47.81  40.47   \n",
       "3      36.5  39.35  ...  44.43  48.91  44.05  46.74   48.06   41.5  26.21   \n",
       "4     39.61  42.65  ...  48.88  53.17  47.95  50.86   52.23  46.37  38.11   \n",
       "...     ...    ...  ...    ...    ...    ...    ...     ...    ...    ...   \n",
       "5473  24.11  27.06  ...  31.89  62.83  43.67  43.01  196.30  66.74  49.73   \n",
       "5474  24.58  27.97  ...  31.89  44.34  35.48  37.34  246.87  69.66  51.21   \n",
       "5475   20.6  23.45  ...  29.69  29.34  28.31  30.46  193.58  66.42  48.51   \n",
       "5476  26.32  29.12  ...  31.71  30.91  30.54   31.3  200.14  69.53  52.47   \n",
       "5477  22.36  24.99  ...  28.27  27.18  26.74  28.21  179.83  62.16  46.32   \n",
       "\n",
       "       HE22   HE23   HE24  \n",
       "0     30.51  -5.31  11.69  \n",
       "1     42.85  42.81  38.67  \n",
       "2     40.25  39.58  36.19  \n",
       "3     30.87  18.47  21.15  \n",
       "4     35.04  22.29  24.85  \n",
       "...     ...    ...    ...  \n",
       "5473  82.25  32.77  28.97  \n",
       "5474   84.2  33.16  28.70  \n",
       "5475  80.84  31.97  26.07  \n",
       "5476   89.8  36.32  30.85  \n",
       "5477  78.85  31.85  27.08  \n",
       "\n",
       "[5478 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_nodes_DA = pd.read_csv(\"../data/part2_selected_nodes_DA.csv\")\n",
    "selected_nodes_DA = selected_nodes_DA.drop(columns=selected_nodes_DA.columns[0])\n",
    "selected_nodes_RT = pd.read_csv(\"../data/part2_selected_nodes_RT.csv\")\n",
    "selected_nodes_RT = selected_nodes_RT.drop(columns=selected_nodes_RT.columns[0])\n",
    "selected_nodes_RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6928fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_cols = [f'HE{i}' for i in range(1,25)]\n",
    "\n",
    "# 0. prep the two master LMP tables\n",
    "selected_nodes_RT_LMP = (\n",
    "    selected_nodes_RT\n",
    "    .query(\"VALUE=='LMP'\")\n",
    "    .assign(\n",
    "        date   = lambda d: pd.to_datetime(d['MARKET_DAY']),\n",
    "        Month  = lambda d: d['date'].dt.month\n",
    "    )\n",
    ")\n",
    "\n",
    "selected_nodes_DA_LMP = (\n",
    "    selected_nodes_DA\n",
    "    .query(\"VALUE=='LMP'\")\n",
    "    .assign(\n",
    "        date   = lambda d: pd.to_datetime(d['MARKET_DAY']),\n",
    "        Month  = lambda d: d['date'].dt.month\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3a104a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [\n",
    "    'AMIL.PSGC1.AMP',\n",
    "    'EES.NINEMILE4',\n",
    "    'NSP.PRISL1',\n",
    "    'EES.SAN_JC1_CT',\n",
    "    'MEC.PPWIND',\n",
    "    'NSP.NWELOAD'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e545344c",
   "metadata": {},
   "source": [
    "## Define methods and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "517caebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import logistic\n",
    "\n",
    "def fit_logistic(data):\n",
    "    # 1) force numeric, turn bad tokens into NaN\n",
    "    y = pd.to_numeric(data['LMP'], errors='coerce').values.astype(float)\n",
    "    # 2) keep only finite values\n",
    "    y = y[np.isfinite(y)]\n",
    "\n",
    "    if len(y) < 2:                       # cannot fit with <2 obs.\n",
    "        return pd.Series({\n",
    "            'count'     : len(y),\n",
    "            'loc'       : np.nan,\n",
    "            'scale'     : np.nan,\n",
    "            'mean_level': np.nan,\n",
    "            'std_level' : np.nan,\n",
    "        })\n",
    "\n",
    "    loc, scale = logistic.fit(y)         # MLE\n",
    "    scale = np.abs(scale)                # ensure scale is positive        \n",
    "        \n",
    "    mean_lvl   = loc\n",
    "    std_lvl    = np.pi * scale / np.sqrt(3)\n",
    "\n",
    "    return pd.Series({\n",
    "        'count'     : len(y),\n",
    "        'loc'       : loc,\n",
    "        'scale'     : scale,\n",
    "        'mean_level': mean_lvl,\n",
    "        'std_level' : std_lvl,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fixed inputs\n",
    "n_miners    = 1_000\n",
    "power_mw    = np.float32(n_miners * 3.25 / 1_000)           # 3.25 MW drawn each hour\n",
    "btc_per_hour = n_miners * 0.00008 / 24          # BTC produced per hour\n",
    "\n",
    "btc_price0  = 93_000\n",
    "sigma_daily = 0.001                              # 1 % daily σ\n",
    "sigma_hour  = sigma_daily / np.sqrt(24)\n",
    "\n",
    "hours  =   8760                       # 8 760 for a full year\n",
    "n_sims = 5_000\n",
    "\n",
    "# --------------------------------------------\n",
    "# 1.  Simulate *all* BTC paths at once\n",
    "# --------------------------------------------\n",
    "rng     = np.random.default_rng(42) # reproducibility\n",
    "\n",
    "eps         = rng.normal(0, sigma_hour, size=(n_sims, hours))\n",
    "btc_paths   = btc_price0 * np.exp(eps).cumprod(axis=1)     # (n_sims,hours)\n",
    "\n",
    "\n",
    "# build hourly index for Jul 1 2025 → Jun 30 2026\n",
    "range = pd.date_range('2025-07-01', '2026-06-30 23:00', freq='h')\n",
    "sim_df = pd.DataFrame({'DT': range})\n",
    "sim_df['Month'] = sim_df.DT.dt.month\n",
    "sim_df['Hour']  = sim_df.DT.dt.hour + 1         # HE1–HE24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e1b54",
   "metadata": {},
   "source": [
    "### Repeat part 1 on all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6142ba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: AMIL.PSGC1.AMP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: EES.NINEMILE4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: NSP.PRISL1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: EES.SAN_JC1_CT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: MEC.PPWIND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: NSP.NWELOAD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1945896658.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "rng_btc = np.random.default_rng(42)\n",
    "eps     = rng_btc.normal(0, sigma_hour, size=(n_sims, hours))\n",
    "btc_paths = btc_price0 * np.exp(eps).cumprod(axis=1)\n",
    "\n",
    "for node in nodes:\n",
    "    print(f\"Processing node: {node}\")\n",
    "    rt = selected_nodes_RT_LMP[selected_nodes_RT_LMP['NODE']==node]\n",
    "    da = selected_nodes_DA_LMP[selected_nodes_DA_LMP['NODE']==node]\n",
    "    \n",
    "    # reshape to long, extracting the hour\n",
    "    DA_long = (\n",
    "        da\n",
    "        .melt(['date','Month'], hour_cols, var_name='HE', value_name='LMP')\n",
    "        .assign(Hour=lambda d: d['HE'].str.extract(r'HE(\\d+)').astype(int))\n",
    "        .drop(columns='HE')\n",
    "        .dropna(subset=['LMP'])\n",
    "    )\n",
    "    RT_long = (\n",
    "        rt\n",
    "        .melt(['date','Month'], hour_cols, var_name='HE', value_name='LMP')\n",
    "        .assign(Hour=lambda d: d['HE'].str.extract(r'HE(\\d+)').astype(int))\n",
    "        .drop(columns='HE')\n",
    "        .dropna(subset=['LMP'])\n",
    "    )\n",
    "\n",
    "    # now fit logistic, merge into sim_df, draw prices & compute P&L exactly as before\n",
    "    lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
    "    lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
    "\n",
    "    sim  = sim_df.copy()\n",
    "    sim_DA = sim.merge(lp_DA[['Month','Hour','loc','scale']], on=['Month','Hour'], how='left')\n",
    "    sim_RT = sim.merge(lp_RT[['Month','Hour','loc','scale']], on=['Month','Hour'], how='left')\n",
    "\n",
    "    P_da = rng_btc.logistic(sim_DA['loc'], sim_DA['scale'], size=(n_sims,hours))\n",
    "    P_rt = rng_btc.logistic(sim_RT['loc'], sim_RT['scale'], size=(n_sims,hours))\n",
    "\n",
    "    prof_da = (btc_per_hour*btc_paths - power_mw*P_da).sum(axis=1)\n",
    "    prof_rt = (btc_per_hour*btc_paths - power_mw*P_rt).sum(axis=1)\n",
    "\n",
    "    rev_mine  = btc_paths * btc_per_hour\n",
    "    cost_mine = power_mw   * P_da\n",
    "    prof1     = rev_mine - cost_mine\n",
    "    prof2     = power_mw*(P_rt - P_da)\n",
    "    neg_prof1 = prof1 < 0\n",
    "    best      = np.maximum(prof1, prof2)\n",
    "    best[neg_prof1] = 0  # set negative profits to zero\n",
    "    prof_ot   = best.sum(axis=1)\n",
    "    opt1_h    = (prof1>prof2).sum(axis=1)\n",
    "    opt2_h    = hours - opt1_h\n",
    "\n",
    "    results.append({\n",
    "      'NODE':     node,\n",
    "      'Mean_DA':  prof_da.mean(),  'Std_DA':  prof_da.std(),\n",
    "      'Mean_RT':  prof_rt.mean(),  'Std_RT':  prof_rt.std(),\n",
    "      'Mean_OT':  prof_ot.mean(),  'Std_OT':  prof_ot.std(),\n",
    "      #'AvgOpt1H': opt1_h.mean(),   'AvgOpt2H': opt2_h.mean(),\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f5d2c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_04174\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_04174_level0_col0\" class=\"col_heading level0 col0\" >NODE</th>\n",
       "      <th id=\"T_04174_level0_col1\" class=\"col_heading level0 col1\" >Mean_DA</th>\n",
       "      <th id=\"T_04174_level0_col2\" class=\"col_heading level0 col2\" >Std_DA</th>\n",
       "      <th id=\"T_04174_level0_col3\" class=\"col_heading level0 col3\" >Mean_RT</th>\n",
       "      <th id=\"T_04174_level0_col4\" class=\"col_heading level0 col4\" >Std_RT</th>\n",
       "      <th id=\"T_04174_level0_col5\" class=\"col_heading level0 col5\" >Mean_OT</th>\n",
       "      <th id=\"T_04174_level0_col6\" class=\"col_heading level0 col6\" >Std_OT</th>\n",
       "      <th id=\"T_04174_level0_col7\" class=\"col_heading level0 col7\" >Sharpe_DA</th>\n",
       "      <th id=\"T_04174_level0_col8\" class=\"col_heading level0 col8\" >Sharpe_RT</th>\n",
       "      <th id=\"T_04174_level0_col9\" class=\"col_heading level0 col9\" >Sharpe_OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04174_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_04174_row0_col0\" class=\"data row0 col0\" >AMIL.PSGC1.AMP</td>\n",
       "      <td id=\"T_04174_row0_col1\" class=\"data row0 col1\" >$1,879,309</td>\n",
       "      <td id=\"T_04174_row0_col2\" class=\"data row0 col2\" >$29,961</td>\n",
       "      <td id=\"T_04174_row0_col3\" class=\"data row0 col3\" >$1,947,369</td>\n",
       "      <td id=\"T_04174_row0_col4\" class=\"data row0 col4\" >$30,073</td>\n",
       "      <td id=\"T_04174_row0_col5\" class=\"data row0 col5\" >$1,885,932</td>\n",
       "      <td id=\"T_04174_row0_col6\" class=\"data row0 col6\" >$29,676</td>\n",
       "      <td id=\"T_04174_row0_col7\" class=\"data row0 col7\" >62.73</td>\n",
       "      <td id=\"T_04174_row0_col8\" class=\"data row0 col8\" >64.76</td>\n",
       "      <td id=\"T_04174_row0_col9\" class=\"data row0 col9\" >63.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04174_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_04174_row1_col0\" class=\"data row1 col0\" >EES.NINEMILE4</td>\n",
       "      <td id=\"T_04174_row1_col1\" class=\"data row1 col1\" >$1,877,082</td>\n",
       "      <td id=\"T_04174_row1_col2\" class=\"data row1 col2\" >$29,836</td>\n",
       "      <td id=\"T_04174_row1_col3\" class=\"data row1 col3\" >$1,939,706</td>\n",
       "      <td id=\"T_04174_row1_col4\" class=\"data row1 col4\" >$29,932</td>\n",
       "      <td id=\"T_04174_row1_col5\" class=\"data row1 col5\" >$1,880,569</td>\n",
       "      <td id=\"T_04174_row1_col6\" class=\"data row1 col6\" >$29,650</td>\n",
       "      <td id=\"T_04174_row1_col7\" class=\"data row1 col7\" >62.91</td>\n",
       "      <td id=\"T_04174_row1_col8\" class=\"data row1 col8\" >64.80</td>\n",
       "      <td id=\"T_04174_row1_col9\" class=\"data row1 col9\" >63.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04174_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_04174_row2_col0\" class=\"data row2 col0\" >NSP.PRISL1</td>\n",
       "      <td id=\"T_04174_row2_col1\" class=\"data row2 col1\" >$1,978,217</td>\n",
       "      <td id=\"T_04174_row2_col2\" class=\"data row2 col2\" >$29,828</td>\n",
       "      <td id=\"T_04174_row2_col3\" class=\"data row2 col3\" >$2,039,817</td>\n",
       "      <td id=\"T_04174_row2_col4\" class=\"data row2 col4\" >$30,151</td>\n",
       "      <td id=\"T_04174_row2_col5\" class=\"data row2 col5\" >$1,983,643</td>\n",
       "      <td id=\"T_04174_row2_col6\" class=\"data row2 col6\" >$29,600</td>\n",
       "      <td id=\"T_04174_row2_col7\" class=\"data row2 col7\" >66.32</td>\n",
       "      <td id=\"T_04174_row2_col8\" class=\"data row2 col8\" >67.65</td>\n",
       "      <td id=\"T_04174_row2_col9\" class=\"data row2 col9\" >67.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04174_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_04174_row3_col0\" class=\"data row3 col0\" >EES.SAN_JC1_CT</td>\n",
       "      <td id=\"T_04174_row3_col1\" class=\"data row3 col1\" >$1,893,177</td>\n",
       "      <td id=\"T_04174_row3_col2\" class=\"data row3 col2\" >$29,824</td>\n",
       "      <td id=\"T_04174_row3_col3\" class=\"data row3 col3\" >$1,955,701</td>\n",
       "      <td id=\"T_04174_row3_col4\" class=\"data row3 col4\" >$30,065</td>\n",
       "      <td id=\"T_04174_row3_col5\" class=\"data row3 col5\" >$1,898,321</td>\n",
       "      <td id=\"T_04174_row3_col6\" class=\"data row3 col6\" >$29,604</td>\n",
       "      <td id=\"T_04174_row3_col7\" class=\"data row3 col7\" >63.48</td>\n",
       "      <td id=\"T_04174_row3_col8\" class=\"data row3 col8\" >65.05</td>\n",
       "      <td id=\"T_04174_row3_col9\" class=\"data row3 col9\" >64.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04174_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_04174_row4_col0\" class=\"data row4 col0\" >MEC.PPWIND</td>\n",
       "      <td id=\"T_04174_row4_col1\" class=\"data row4 col1\" >$2,165,346</td>\n",
       "      <td id=\"T_04174_row4_col2\" class=\"data row4 col2\" >$30,198</td>\n",
       "      <td id=\"T_04174_row4_col3\" class=\"data row4 col3\" >$2,221,185</td>\n",
       "      <td id=\"T_04174_row4_col4\" class=\"data row4 col4\" >$49,441</td>\n",
       "      <td id=\"T_04174_row4_col5\" class=\"data row4 col5\" >$2,250,529</td>\n",
       "      <td id=\"T_04174_row4_col6\" class=\"data row4 col6\" >$37,177</td>\n",
       "      <td id=\"T_04174_row4_col7\" class=\"data row4 col7\" >71.71</td>\n",
       "      <td id=\"T_04174_row4_col8\" class=\"data row4 col8\" >44.93</td>\n",
       "      <td id=\"T_04174_row4_col9\" class=\"data row4 col9\" >60.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04174_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_04174_row5_col0\" class=\"data row5 col0\" >NSP.NWELOAD</td>\n",
       "      <td id=\"T_04174_row5_col1\" class=\"data row5 col1\" >$1,835,564</td>\n",
       "      <td id=\"T_04174_row5_col2\" class=\"data row5 col2\" >$29,947</td>\n",
       "      <td id=\"T_04174_row5_col3\" class=\"data row5 col3\" >$1,918,088</td>\n",
       "      <td id=\"T_04174_row5_col4\" class=\"data row5 col4\" >$30,350</td>\n",
       "      <td id=\"T_04174_row5_col5\" class=\"data row5 col5\" >$1,846,849</td>\n",
       "      <td id=\"T_04174_row5_col6\" class=\"data row5 col6\" >$29,491</td>\n",
       "      <td id=\"T_04174_row5_col7\" class=\"data row5 col7\" >61.29</td>\n",
       "      <td id=\"T_04174_row5_col8\" class=\"data row5 col8\" >63.20</td>\n",
       "      <td id=\"T_04174_row5_col9\" class=\"data row5 col9\" >62.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21dbf26d9c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. compute Sharpe ratios\n",
    "summary['Sharpe_DA'] = summary['Mean_DA'] / summary['Std_DA']\n",
    "summary['Sharpe_RT'] = summary['Mean_RT'] / summary['Std_RT']\n",
    "summary['Sharpe_OT'] = summary['Mean_OT'] / summary['Std_OT']\n",
    "\n",
    "# 2. create a styled DataFrame with $ + commas, no scientific notation\n",
    "fmt = {\n",
    "    'Mean_DA'  : '${:,.0f}', 'Std_DA'  : '${:,.0f}',\n",
    "    'Mean_RT'  : '${:,.0f}', 'Std_RT'  : '${:,.0f}',\n",
    "    'Mean_OT'  : '${:,.0f}', 'Std_OT'  : '${:,.0f}',\n",
    "    'Sharpe_DA': '{:.2f}',   'Sharpe_RT': '{:.2f}',\n",
    "    'Sharpe_OT': '{:.2f}',\n",
    "    'AvgOpt1H' : '{:,.1f}',  'AvgOpt2H': '{:,.1f}'\n",
    "}\n",
    "\n",
    "summary = summary.style.format(fmt)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03182c10",
   "metadata": {},
   "source": [
    "$\\textbf{Commentary}: $ Even tough the optimal strategy does not always have the best sharpe ratio, we see that it provides consistent metrics across all nodes (which is no the case for the naive strategies). This is a good thing, when investing, to have consistent performence.\n",
    "\n",
    "However, probably that when investing on a specific node, doing more research on the price statistics could lead to higher performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da8608",
   "metadata": {},
   "source": [
    "## Adding a node or doubling the size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5b1fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_RT_original = pd.read_csv(\"../data/Node_RT.csv\")\n",
    "node_DA_original = pd.read_csv(\"../data/Node_DA_LMP.csv\")\n",
    "\n",
    "node_RT_LMP_original = node_RT_original[node_RT_original['VALUE'] == 'LMP']\n",
    "node_RT_LMP_original = node_RT_LMP_original.drop(columns=node_RT_LMP_original.columns[0])#.set_index('MARKET_DAY')\n",
    "node_RT_LMP_original['date'] = pd.to_datetime(node_RT_LMP_original['MARKET_DAY']) \n",
    "node_RT_LMP_original['Month'] = node_RT_LMP_original['date'].dt.month\n",
    "node_DA_LMP_original = node_DA_original\n",
    "node_DA_LMP_original['date'] = pd.to_datetime(node_DA_LMP_original['MARKET_DAY'])\n",
    "node_DA_LMP_original['Month'] = node_DA_LMP_original['date'].dt.month\n",
    "node_DA_LMP_original.drop(columns=[\"source_zip\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "141803bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_long_original  = (\n",
    "    node_DA_LMP_original\n",
    "    .melt(id_vars=['date', 'Month'], value_vars=hour_cols,\n",
    "          var_name='Hour', value_name='LMP')\n",
    "    .assign(Hour=lambda d: d['Hour'].str.extract(r'HE(\\d+)').astype(int))\n",
    "    .dropna(subset=['LMP'])\n",
    ")\n",
    "\n",
    "RT_long_original = (\n",
    "    node_RT_LMP_original\n",
    "    .melt(id_vars=['date', 'Month'], value_vars=hour_cols,\n",
    "          var_name='Hour', value_name='LMP')\n",
    "    .assign(Hour=lambda d: d['Hour'].str.extract(r'HE(\\d+)').astype(int))\n",
    "    .dropna(subset=['LMP'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f02be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\2962648125.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(fit_logistic)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\2962648125.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(fit_logistic)\n"
     ]
    }
   ],
   "source": [
    "# ── Apply to DA and RT data ──────────────────────────────────────────\n",
    "logistic_params_DA_original = (\n",
    "    DA_long_original.groupby(['Month', 'Hour'])\n",
    "           .apply(fit_logistic)\n",
    "           .reset_index()\n",
    ")\n",
    "\n",
    "logistic_params_RT_original = (\n",
    "    RT_long_original.groupby(['Month', 'Hour'])\n",
    "           .apply(fit_logistic)\n",
    "           .reset_index()\n",
    ")\n",
    "\n",
    "sim_df_DA_original = sim_df.merge(logistic_params_DA_original[['mean_level','scale','std_level','Month','Hour']], on=['Month','Hour'], how='left')\n",
    "sim_df_RT_original = sim_df.merge(logistic_params_RT_original[['mean_level','scale','std_level','Month','Hour']], on=['Month','Hour'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eba3d9",
   "metadata": {},
   "source": [
    "### apply optimal strategy to original node to get hourly pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f797ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_draw(mean, scale):\n",
    "    loc   = mean.values.astype('float32')  \n",
    "    scale_val = scale.values.astype('float32')  \n",
    "    return rng.logistic(loc, scale_val, size=(n_sims, hours))   # (n_sims,hours)\n",
    "\n",
    "rng     = np.random.default_rng(42) # reproducibility\n",
    "\n",
    "P_rt_original = logistic_draw(sim_df_RT_original['mean_level'], sim_df_RT_original['scale'])\n",
    "P_da_original = logistic_draw(sim_df_DA_original['mean_level'], sim_df_DA_original['scale'])\n",
    "\n",
    "#  Compute both profit options per hour\n",
    "rev_mine  = btc_paths * btc_per_hour                # $ from mining\n",
    "cost_powd_da  = power_mw * P_da_original                         # $ cost of power in DA to mine\n",
    "cost_powd_rt  = power_mw * P_rt_original                         # $ cost of power in RT to mine\n",
    "\n",
    "prof1 = rev_mine - cost_powd_da                         # mining option\n",
    "prof2 = power_mw * (P_rt_original - P_da_original)                    # sell DA power back in RT market\n",
    "\n",
    "## Da strat\n",
    "pnl_da_original = prof1.sum(axis=1)  # (n_sims,)\n",
    "#  RT strat\n",
    "pnl_rt_original = (rev_mine - cost_powd_rt).sum(axis=1)  # (n_sims,)\n",
    "\n",
    "#  Choose best option per hour & accumulate\n",
    "best_pnl   = np.maximum(prof1, prof2)               # (n_sims,hours)\n",
    "best_pnl[prof1 < 0] = 0                            # set negative profits to zero\n",
    "profits_OT_original = best_pnl.sum(axis=1)                   # (n_sims,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd97eb5",
   "metadata": {},
   "source": [
    "## Now we consider having 2 nodes: Original + another\n",
    "\n",
    "Therefore we sum the hourly pnl and compute the statistics on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28128dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: AMIL.PSGC1.AMP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: EES.NINEMILE4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: NSP.PRISL1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: EES.SAN_JC1_CT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: MEC.PPWIND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node: NSP.NWELOAD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_26952\\1549991044.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n"
     ]
    }
   ],
   "source": [
    "results_2_nodes = []\n",
    "\n",
    "rng_btc = np.random.default_rng(42)\n",
    "eps     = rng_btc.normal(0, sigma_hour, size=(n_sims, hours))\n",
    "btc_paths = btc_price0 * np.exp(eps).cumprod(axis=1)\n",
    "\n",
    "for node in nodes:\n",
    "    print(f\"Processing node: {node}\")\n",
    "    rt = selected_nodes_RT_LMP[selected_nodes_RT_LMP['NODE']==node]\n",
    "    da = selected_nodes_DA_LMP[selected_nodes_DA_LMP['NODE']==node]\n",
    "    \n",
    "    # reshape to long, extracting the hour\n",
    "    DA_long = (\n",
    "        da\n",
    "        .melt(['date','Month'], hour_cols, var_name='HE', value_name='LMP')\n",
    "        .assign(Hour=lambda d: d['HE'].str.extract(r'HE(\\d+)').astype(int))\n",
    "        .drop(columns='HE')\n",
    "        .dropna(subset=['LMP'])\n",
    "    )\n",
    "    RT_long = (\n",
    "        rt\n",
    "        .melt(['date','Month'], hour_cols, var_name='HE', value_name='LMP')\n",
    "        .assign(Hour=lambda d: d['HE'].str.extract(r'HE(\\d+)').astype(int))\n",
    "        .drop(columns='HE')\n",
    "        .dropna(subset=['LMP'])\n",
    "    )\n",
    "\n",
    "    # now fit logistic, merge into sim_df, draw prices & compute P&L exactly as before\n",
    "    lp_DA = DA_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
    "    lp_RT = RT_long.groupby(['Month','Hour']).apply(fit_logistic).reset_index()\n",
    "\n",
    "    sim  = sim_df.copy()\n",
    "    sim_DA = sim.merge(lp_DA[['Month','Hour','loc','scale']], on=['Month','Hour'], how='left')\n",
    "    sim_RT = sim.merge(lp_RT[['Month','Hour','loc','scale']], on=['Month','Hour'], how='left')\n",
    "\n",
    "    P_da = rng_btc.logistic(sim_DA['loc'], sim_DA['scale'], size=(n_sims,hours))\n",
    "    P_rt = rng_btc.logistic(sim_RT['loc'], sim_RT['scale'], size=(n_sims,hours))\n",
    "\n",
    "    prof_da = (btc_per_hour*btc_paths - power_mw*P_da).sum(axis=1)\n",
    "    prof_da_2_nodes = prof_da + pnl_da_original\n",
    "    prof_rt = (btc_per_hour*btc_paths - power_mw*P_rt).sum(axis=1)\n",
    "    prof_rt_2_nodes = prof_rt + pnl_rt_original\n",
    "\n",
    "    rev_mine  = btc_paths * btc_per_hour\n",
    "    cost_mine = power_mw   * P_da\n",
    "    prof1     = rev_mine - cost_mine\n",
    "    prof2     = power_mw*(P_rt - P_da)\n",
    "    neg_prof1 = prof1 < 0\n",
    "    best      = np.maximum(prof1, prof2)\n",
    "    best[neg_prof1] = 0  # set negative profits to zero\n",
    "    prof_ot   = best.sum(axis=1)\n",
    "    prof_OT_2_nodes = profits_OT_original + prof_ot\n",
    "\n",
    "    results_2_nodes.append({\n",
    "      'NODE':     node,\n",
    "      'Mean_DA':  prof_da_2_nodes.mean(),  'Std_DA':  prof_da_2_nodes.std(),\n",
    "      'Mean_RT':  prof_rt_2_nodes.mean(),  'Std_RT':  prof_rt_2_nodes.std(),\n",
    "      'Mean_OT':  prof_OT_2_nodes.mean(),  'Std_OT':  prof_OT_2_nodes.std(),\n",
    "      #'AvgOpt1H': opt1_h.mean(),   'AvgOpt2H': opt2_h.mean(),\n",
    "    })\n",
    "\n",
    "summary2 = pd.DataFrame(results_2_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2e9075b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_aae13\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aae13_level0_col0\" class=\"col_heading level0 col0\" >Orginal Node + Node</th>\n",
       "      <th id=\"T_aae13_level0_col1\" class=\"col_heading level0 col1\" >Mean_DA</th>\n",
       "      <th id=\"T_aae13_level0_col2\" class=\"col_heading level0 col2\" >Std_DA</th>\n",
       "      <th id=\"T_aae13_level0_col3\" class=\"col_heading level0 col3\" >Mean_RT</th>\n",
       "      <th id=\"T_aae13_level0_col4\" class=\"col_heading level0 col4\" >Std_RT</th>\n",
       "      <th id=\"T_aae13_level0_col5\" class=\"col_heading level0 col5\" >Mean_OT</th>\n",
       "      <th id=\"T_aae13_level0_col6\" class=\"col_heading level0 col6\" >Std_OT</th>\n",
       "      <th id=\"T_aae13_level0_col7\" class=\"col_heading level0 col7\" >Sharpe_DA</th>\n",
       "      <th id=\"T_aae13_level0_col8\" class=\"col_heading level0 col8\" >Sharpe_RT</th>\n",
       "      <th id=\"T_aae13_level0_col9\" class=\"col_heading level0 col9\" >Sharpe_OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aae13_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aae13_row0_col0\" class=\"data row0 col0\" >AMIL.PSGC1.AMP</td>\n",
       "      <td id=\"T_aae13_row0_col1\" class=\"data row0 col1\" >$3,714,922</td>\n",
       "      <td id=\"T_aae13_row0_col2\" class=\"data row0 col2\" >$59,667</td>\n",
       "      <td id=\"T_aae13_row0_col3\" class=\"data row0 col3\" >$3,865,547</td>\n",
       "      <td id=\"T_aae13_row0_col4\" class=\"data row0 col4\" >$59,721</td>\n",
       "      <td id=\"T_aae13_row0_col5\" class=\"data row0 col5\" >$3,732,808</td>\n",
       "      <td id=\"T_aae13_row0_col6\" class=\"data row0 col6\" >$58,914</td>\n",
       "      <td id=\"T_aae13_row0_col7\" class=\"data row0 col7\" >61.590817</td>\n",
       "      <td id=\"T_aae13_row0_col8\" class=\"data row0 col8\" >64.057404</td>\n",
       "      <td id=\"T_aae13_row0_col9\" class=\"data row0 col9\" >62.681252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae13_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aae13_row1_col0\" class=\"data row1 col0\" >EES.NINEMILE4</td>\n",
       "      <td id=\"T_aae13_row1_col1\" class=\"data row1 col1\" >$3,712,695</td>\n",
       "      <td id=\"T_aae13_row1_col2\" class=\"data row1 col2\" >$59,570</td>\n",
       "      <td id=\"T_aae13_row1_col3\" class=\"data row1 col3\" >$3,857,884</td>\n",
       "      <td id=\"T_aae13_row1_col4\" class=\"data row1 col4\" >$59,660</td>\n",
       "      <td id=\"T_aae13_row1_col5\" class=\"data row1 col5\" >$3,727,446</td>\n",
       "      <td id=\"T_aae13_row1_col6\" class=\"data row1 col6\" >$58,919</td>\n",
       "      <td id=\"T_aae13_row1_col7\" class=\"data row1 col7\" >61.653480</td>\n",
       "      <td id=\"T_aae13_row1_col8\" class=\"data row1 col8\" >63.994042</td>\n",
       "      <td id=\"T_aae13_row1_col9\" class=\"data row1 col9\" >62.585312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae13_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aae13_row2_col0\" class=\"data row2 col0\" >NSP.PRISL1</td>\n",
       "      <td id=\"T_aae13_row2_col1\" class=\"data row2 col1\" >$3,813,830</td>\n",
       "      <td id=\"T_aae13_row2_col2\" class=\"data row2 col2\" >$59,528</td>\n",
       "      <td id=\"T_aae13_row2_col3\" class=\"data row2 col3\" >$3,957,995</td>\n",
       "      <td id=\"T_aae13_row2_col4\" class=\"data row2 col4\" >$59,771</td>\n",
       "      <td id=\"T_aae13_row2_col5\" class=\"data row2 col5\" >$3,830,520</td>\n",
       "      <td id=\"T_aae13_row2_col6\" class=\"data row2 col6\" >$58,836</td>\n",
       "      <td id=\"T_aae13_row2_col7\" class=\"data row2 col7\" >63.395359</td>\n",
       "      <td id=\"T_aae13_row2_col8\" class=\"data row2 col8\" >65.550617</td>\n",
       "      <td id=\"T_aae13_row2_col9\" class=\"data row2 col9\" >64.425562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae13_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aae13_row3_col0\" class=\"data row3 col0\" >EES.SAN_JC1_CT</td>\n",
       "      <td id=\"T_aae13_row3_col1\" class=\"data row3 col1\" >$3,728,790</td>\n",
       "      <td id=\"T_aae13_row3_col2\" class=\"data row3 col2\" >$59,542</td>\n",
       "      <td id=\"T_aae13_row3_col3\" class=\"data row3 col3\" >$3,873,879</td>\n",
       "      <td id=\"T_aae13_row3_col4\" class=\"data row3 col4\" >$59,762</td>\n",
       "      <td id=\"T_aae13_row3_col5\" class=\"data row3 col5\" >$3,745,198</td>\n",
       "      <td id=\"T_aae13_row3_col6\" class=\"data row3 col6\" >$58,859</td>\n",
       "      <td id=\"T_aae13_row3_col7\" class=\"data row3 col7\" >61.953059</td>\n",
       "      <td id=\"T_aae13_row3_col8\" class=\"data row3 col8\" >64.152122</td>\n",
       "      <td id=\"T_aae13_row3_col9\" class=\"data row3 col9\" >62.950635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae13_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aae13_row4_col0\" class=\"data row4 col0\" >MEC.PPWIND</td>\n",
       "      <td id=\"T_aae13_row4_col1\" class=\"data row4 col1\" >$4,000,959</td>\n",
       "      <td id=\"T_aae13_row4_col2\" class=\"data row4 col2\" >$59,737</td>\n",
       "      <td id=\"T_aae13_row4_col3\" class=\"data row4 col3\" >$4,139,363</td>\n",
       "      <td id=\"T_aae13_row4_col4\" class=\"data row4 col4\" >$71,837</td>\n",
       "      <td id=\"T_aae13_row4_col5\" class=\"data row4 col5\" >$4,097,406</td>\n",
       "      <td id=\"T_aae13_row4_col6\" class=\"data row4 col6\" >$62,937</td>\n",
       "      <td id=\"T_aae13_row4_col7\" class=\"data row4 col7\" >66.306842</td>\n",
       "      <td id=\"T_aae13_row4_col8\" class=\"data row4 col8\" >57.064980</td>\n",
       "      <td id=\"T_aae13_row4_col9\" class=\"data row4 col9\" >64.467485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae13_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_aae13_row5_col0\" class=\"data row5 col0\" >NSP.NWELOAD</td>\n",
       "      <td id=\"T_aae13_row5_col1\" class=\"data row5 col1\" >$3,671,178</td>\n",
       "      <td id=\"T_aae13_row5_col2\" class=\"data row5 col2\" >$59,607</td>\n",
       "      <td id=\"T_aae13_row5_col3\" class=\"data row5 col3\" >$3,836,266</td>\n",
       "      <td id=\"T_aae13_row5_col4\" class=\"data row5 col4\" >$59,896</td>\n",
       "      <td id=\"T_aae13_row5_col5\" class=\"data row5 col5\" >$3,693,726</td>\n",
       "      <td id=\"T_aae13_row5_col6\" class=\"data row5 col6\" >$58,685</td>\n",
       "      <td id=\"T_aae13_row5_col7\" class=\"data row5 col7\" >60.918971</td>\n",
       "      <td id=\"T_aae13_row5_col8\" class=\"data row5 col8\" >63.381392</td>\n",
       "      <td id=\"T_aae13_row5_col9\" class=\"data row5 col9\" >62.260211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21d802fce50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. compute Sharpe ratios\n",
    "rf = 0.04 \n",
    "initial_investment_2 = 2*500_000  # Initial investment in USD\n",
    "rf_return_2 = initial_investment_2 * rf  # Risk-free return over the period\n",
    "summary2['Sharpe_DA'] = (summary2['Mean_DA']-rf_return_2) / summary2['Std_DA']\n",
    "summary2['Sharpe_RT'] = (summary2['Mean_RT']-rf_return_2) / summary2['Std_RT']\n",
    "summary2['Sharpe_OT'] = (summary2['Mean_OT']-rf_return_2) / summary2['Std_OT']\n",
    "\n",
    "# 2. create a styled DataFrame with $ + commas, no scientific notation\n",
    "fmt = {\n",
    "    'Mean_DA'  : '${:,.0f}', 'Std_DA'  : '${:,.0f}',\n",
    "    'Mean_RT'  : '${:,.0f}', 'Std_RT'  : '${:,.0f}',\n",
    "    'Mean_OT'  : '${:,.0f}', 'Std_OT'  : '${:,.0f}',\n",
    "    'Sortino_DA': '{:.2f}',   'Sortino_RT': '{:.2f}',\n",
    "    'Sortino_OT': '{:.2f}',\n",
    "    'AvgOpt1H' : '{:,.1f}',  'AvgOpt2H': '{:,.1f}'\n",
    "}\n",
    "summary2.rename(columns={'NODE': 'Orginal Node + Node'}, inplace=True)\n",
    "summary2 = summary2.style.format(fmt)\n",
    "\n",
    "summary2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff748cb7",
   "metadata": {},
   "source": [
    "Comparing with Part 1, we see that through diversification (of nodes), we always achieve higher ratios than just doubling the investment at the original node. We see that for some nodes there is almost no improvement, whereas for other we achieve a slight better performence (recall the Sortino ratio for 2 original nodes = Sortino Ratio for 1 original node = 61.93)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
